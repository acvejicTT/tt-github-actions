{
    "benchmarks_summary": [
        {
            "isl": 128,
            "osl": 128,
            "max_concurrency": 1,
            "ttft": 134.7,
            "tput_user": 64.37,
            "tput": 64.4,
            "target_checks": {
                "functional": {
                    "ttft": 60.0,
                    "ttft_ratio": 2.2449999999999997,
                    "ttft_check": 3,
                    "tput_user": 18.3,
                    "tput_user_ratio": 3.517486338797814,
                    "tput_user_check": 2,
                    "tput_check": 1
                },
                "complete": {
                    "ttft": 12.0,
                    "ttft_ratio": 11.225,
                    "ttft_check": 3,
                    "tput_user": 91.5,
                    "tput_user_ratio": 0.7034972677595629,
                    "tput_user_check": 3,
                    "tput_check": 1
                },
                "target": {
                    "ttft": 7.5,
                    "ttft_ratio": 17.959999999999997,
                    "ttft_check": 3,
                    "tput_user": 146.4,
                    "tput_user_ratio": 0.43968579234972677,
                    "tput_user_check": 3,
                    "tput_check": 1
                }
            }
        }
    ],
    "evals": [
        {
            "model": "Llama-3.2-1B-Instruct",
            "device": "t3k",
            "task_name": "meta_gpqa",
            "accuracy_check": 2,
            "score": 28.125,
            "ratio_to_reference": 1.0412810070344316,
            "gpu_reference_score": 27.01,
            "gpu_reference_score_ref": "https://github.com/tenstorrent/tt-inference-server/issues/139#issuecomment-2761649617",
            "ratio_to_published": 1.0340073529411764,
            "published_score": 27.2,
            "published_score_ref": "https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct#instruction-tuned-models",
            "metadata": {
                "dataset_path": "meta-llama/Llama-3.2-1B-Instruct-evals"
            }
        }
    ],
    "benchmarks": [
        {
            "timestamp": "2025-06-02_09-06-19",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "128",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "134.7",
            "std_ttft_ms": "3.03",
            "mean_tpot_ms": "15.5",
            "std_tpot_ms": "0.27",
            "mean_tps": "64.37",
            "std_tps": "1.12",
            "tps_decode_throughput": "64.4",
            "tps_prefill_throughput": "950.3",
            "mean_e2el_ms": "2107.7",
            "request_throughput": "0.474",
            "total_input_tokens": "1024",
            "total_output_tokens": "1024",
            "num_prompts": "8",
            "num_requests": "8",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-06-19_isl-128_osl-128_maxcon-1_n-8.json"
        },
        {
            "timestamp": "2025-06-02_09-09-18",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "128",
            "output_sequence_length": "1024",
            "max_con": "1",
            "mean_ttft_ms": "205.5",
            "std_ttft_ms": "3.54",
            "mean_tpot_ms": "15.8",
            "std_tpot_ms": "0.08",
            "mean_tps": "63.14",
            "std_tps": "0.3",
            "tps_decode_throughput": "63.1",
            "tps_prefill_throughput": "622.7",
            "mean_e2el_ms": "16407.3",
            "request_throughput": "0.061",
            "total_input_tokens": "512",
            "total_output_tokens": "4096",
            "num_prompts": "4",
            "num_requests": "4",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-09-18_isl-128_osl-1024_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-06-02_09-10-46",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "1024",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "137.7",
            "std_ttft_ms": "7.59",
            "mean_tpot_ms": "15.6",
            "std_tpot_ms": "0.54",
            "mean_tps": "64.25",
            "std_tps": "2.15",
            "tps_decode_throughput": "64.2",
            "tps_prefill_throughput": "7434.5",
            "mean_e2el_ms": "2114.4",
            "request_throughput": "0.473",
            "total_input_tokens": "4096",
            "total_output_tokens": "512",
            "num_prompts": "4",
            "num_requests": "4",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-10-46_isl-1024_osl-128_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-06-02_09-11-02",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "2048",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "181.3",
            "std_ttft_ms": "3.88",
            "mean_tpot_ms": "16.6",
            "std_tpot_ms": "0.05",
            "mean_tps": "60.09",
            "std_tps": "0.19",
            "tps_decode_throughput": "60.1",
            "tps_prefill_throughput": "11294.4",
            "mean_e2el_ms": "2294.8",
            "request_throughput": "0.435",
            "total_input_tokens": "8192",
            "total_output_tokens": "512",
            "num_prompts": "4",
            "num_requests": "4",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-11-02_isl-2048_osl-128_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-06-02_09-11-19",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "3072",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "184.0",
            "std_ttft_ms": "4.54",
            "mean_tpot_ms": "16.9",
            "std_tpot_ms": "0.04",
            "mean_tps": "59.33",
            "std_tps": "0.15",
            "tps_decode_throughput": "59.3",
            "tps_prefill_throughput": "16693.3",
            "mean_e2el_ms": "2324.4",
            "request_throughput": "0.43",
            "total_input_tokens": "12288",
            "total_output_tokens": "512",
            "num_prompts": "4",
            "num_requests": "4",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-11-19_isl-3072_osl-128_maxcon-1_n-4.json"
        },
        {
            "timestamp": "2025-06-02_09-11-37",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "4096",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "274.3",
            "std_ttft_ms": "2.66",
            "mean_tpot_ms": "17.3",
            "std_tpot_ms": "0.0",
            "mean_tps": "57.84",
            "std_tps": "0.0",
            "tps_decode_throughput": "57.8",
            "tps_prefill_throughput": "14934.1",
            "mean_e2el_ms": "2469.8",
            "request_throughput": "0.404",
            "total_input_tokens": "8192",
            "total_output_tokens": "256",
            "num_prompts": "2",
            "num_requests": "2",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-11-37_isl-4096_osl-128_maxcon-1_n-2.json"
        },
        {
            "timestamp": "2025-06-02_09-11-50",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "8192",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "447.6",
            "std_ttft_ms": "1.21",
            "mean_tpot_ms": "17.7",
            "std_tpot_ms": "0.03",
            "mean_tps": "56.36",
            "std_tps": "0.1",
            "tps_decode_throughput": "56.4",
            "tps_prefill_throughput": "18301.9",
            "mean_e2el_ms": "2700.8",
            "request_throughput": "0.37",
            "total_input_tokens": "16384",
            "total_output_tokens": "256",
            "num_prompts": "2",
            "num_requests": "2",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-11-50_isl-8192_osl-128_maxcon-1_n-2.json"
        },
        {
            "timestamp": "2025-06-02_09-12-11",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "16384",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "945.3",
            "std_ttft_ms": "5.81",
            "mean_tpot_ms": "21.5",
            "std_tpot_ms": "0.18",
            "mean_tps": "46.45",
            "std_tps": "0.39",
            "tps_decode_throughput": "46.5",
            "tps_prefill_throughput": "17332.4",
            "mean_e2el_ms": "3679.4",
            "request_throughput": "0.272",
            "total_input_tokens": "32768",
            "total_output_tokens": "256",
            "num_prompts": "2",
            "num_requests": "2",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-12-11_isl-16384_osl-128_maxcon-1_n-2.json"
        },
        {
            "timestamp": "2025-06-02_09-12-35",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "32000",
            "output_sequence_length": "128",
            "max_con": "1",
            "mean_ttft_ms": "2484.2",
            "std_ttft_ms": "161.26",
            "mean_tpot_ms": "27.6",
            "std_tpot_ms": "0.05",
            "mean_tps": "36.28",
            "std_tps": "0.06",
            "tps_decode_throughput": "36.3",
            "tps_prefill_throughput": "12881.2",
            "mean_e2el_ms": "5984.5",
            "request_throughput": "0.167",
            "total_input_tokens": "64000",
            "total_output_tokens": "256",
            "num_prompts": "2",
            "num_requests": "2",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-12-35_isl-32000_osl-128_maxcon-1_n-2.json"
        },
        {
            "timestamp": "2025-06-02_09-13-06",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "128",
            "output_sequence_length": "128",
            "max_con": "32",
            "mean_ttft_ms": "2761.3",
            "std_ttft_ms": "199.08",
            "mean_tpot_ms": "17.3",
            "std_tpot_ms": "0.62",
            "mean_tps": "57.65",
            "std_tps": "2.0",
            "tps_decode_throughput": "1844.9",
            "tps_prefill_throughput": "1483.4",
            "mean_e2el_ms": "4964.2",
            "request_throughput": "6.413",
            "total_input_tokens": "32768",
            "total_output_tokens": "32768",
            "num_prompts": "256",
            "num_requests": "256",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-13-06_isl-128_osl-128_maxcon-32_n-256.json"
        },
        {
            "timestamp": "2025-06-02_09-13-53",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "128",
            "output_sequence_length": "1024",
            "max_con": "32",
            "mean_ttft_ms": "2785.8",
            "std_ttft_ms": "79.25",
            "mean_tpot_ms": "19.0",
            "std_tpot_ms": "0.31",
            "mean_tps": "52.65",
            "std_tps": "0.85",
            "tps_decode_throughput": "1684.8",
            "tps_prefill_throughput": "1470.3",
            "mean_e2el_ms": "22216.3",
            "request_throughput": "1.439",
            "total_input_tokens": "16384",
            "total_output_tokens": "131072",
            "num_prompts": "128",
            "num_requests": "128",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-13-53_isl-128_osl-1024_maxcon-32_n-128.json"
        },
        {
            "timestamp": "2025-06-02_09-15-44",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "2048",
            "output_sequence_length": "128",
            "max_con": "32",
            "mean_ttft_ms": "4457.8",
            "std_ttft_ms": "251.99",
            "mean_tpot_ms": "19.4",
            "std_tpot_ms": "0.18",
            "mean_tps": "51.45",
            "std_tps": "0.48",
            "tps_decode_throughput": "1646.3",
            "tps_prefill_throughput": "14701.3",
            "mean_e2el_ms": "6926.4",
            "request_throughput": "4.601",
            "total_input_tokens": "262144",
            "total_output_tokens": "16384",
            "num_prompts": "128",
            "num_requests": "128",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-15-44_isl-2048_osl-128_maxcon-32_n-128.json"
        },
        {
            "timestamp": "2025-06-02_09-16-20",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "2048",
            "output_sequence_length": "2048",
            "max_con": "32",
            "mean_ttft_ms": "4092.9",
            "std_ttft_ms": "471.52",
            "mean_tpot_ms": "21.2",
            "std_tpot_ms": "0.94",
            "mean_tps": "47.06",
            "std_tps": "2.0",
            "tps_decode_throughput": "1505.9",
            "tps_prefill_throughput": "16012.3",
            "mean_e2el_ms": "47591.2",
            "request_throughput": "0.645",
            "total_input_tokens": "131072",
            "total_output_tokens": "131072",
            "num_prompts": "64",
            "num_requests": "64",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-16-20_isl-2048_osl-2048_maxcon-32_n-64.json"
        },
        {
            "timestamp": "2025-06-02_09-18-39",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "3000",
            "output_sequence_length": "64",
            "max_con": "32",
            "mean_ttft_ms": "4486.0",
            "std_ttft_ms": "242.72",
            "mean_tpot_ms": "17.4",
            "std_tpot_ms": "0.59",
            "mean_tps": "57.62",
            "std_tps": "1.9",
            "tps_decode_throughput": "1844.0",
            "tps_prefill_throughput": "21399.8",
            "mean_e2el_ms": "5579.3",
            "request_throughput": "5.706",
            "total_input_tokens": "384000",
            "total_output_tokens": "8192",
            "num_prompts": "128",
            "num_requests": "128",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-18-39_isl-3000_osl-64_maxcon-32_n-128.json"
        },
        {
            "timestamp": "2025-06-02_09-19-09",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "4000",
            "output_sequence_length": "64",
            "max_con": "32",
            "mean_ttft_ms": "6449.5",
            "std_ttft_ms": "1252.98",
            "mean_tpot_ms": "25.2",
            "std_tpot_ms": "17.34",
            "mean_tps": "39.73",
            "std_tps": "16.21",
            "tps_decode_throughput": "1271.2",
            "tps_prefill_throughput": "19846.6",
            "mean_e2el_ms": "8035.3",
            "request_throughput": "3.807",
            "total_input_tokens": "512000",
            "total_output_tokens": "8192",
            "num_prompts": "128",
            "num_requests": "128",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-19-09_isl-4000_osl-64_maxcon-32_n-128.json"
        },
        {
            "timestamp": "2025-06-02_09-19-50",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "4500",
            "output_sequence_length": "64",
            "max_con": "32",
            "mean_ttft_ms": "6541.9",
            "std_ttft_ms": "2411.99",
            "mean_tpot_ms": "18.1",
            "std_tpot_ms": "0.23",
            "mean_tps": "55.31",
            "std_tps": "0.7",
            "tps_decode_throughput": "1770.0",
            "tps_prefill_throughput": "22011.8",
            "mean_e2el_ms": "7680.9",
            "request_throughput": "3.635",
            "total_input_tokens": "288000",
            "total_output_tokens": "4096",
            "num_prompts": "64",
            "num_requests": "64",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-19-50_isl-4500_osl-64_maxcon-32_n-64.json"
        },
        {
            "timestamp": "2025-06-02_09-20-16",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "8000",
            "output_sequence_length": "64",
            "max_con": "32",
            "mean_ttft_ms": "11655.0",
            "std_ttft_ms": "3187.88",
            "mean_tpot_ms": "17.2",
            "std_tpot_ms": "0.17",
            "mean_tps": "58.21",
            "std_tps": "0.56",
            "tps_decode_throughput": "1862.7",
            "tps_prefill_throughput": "21964.9",
            "mean_e2el_ms": "12737.2",
            "request_throughput": "2.125",
            "total_input_tokens": "512000",
            "total_output_tokens": "4096",
            "num_prompts": "64",
            "num_requests": "64",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-20-16_isl-8000_osl-64_maxcon-32_n-64.json"
        },
        {
            "timestamp": "2025-06-02_09-20-54",
            "model_name": "id_tt-transformers_Llama-3.2-1B-Instruct",
            "model_id": "meta-llama/Llama-3.2-1B-Instruct",
            "backend": "vllm",
            "device": "t3k",
            "input_sequence_length": "16000",
            "output_sequence_length": "64",
            "max_con": "32",
            "mean_ttft_ms": "26177.5",
            "std_ttft_ms": "8395.33",
            "mean_tpot_ms": "21.6",
            "std_tpot_ms": "0.67",
            "mean_tps": "46.23",
            "std_tps": "1.39",
            "tps_decode_throughput": "1479.4",
            "tps_prefill_throughput": "19558.8",
            "mean_e2el_ms": "27540.2",
            "request_throughput": "0.928",
            "total_input_tokens": "1024000",
            "total_output_tokens": "4096",
            "num_prompts": "64",
            "num_requests": "64",
            "filename": "benchmark_id_tt-transformers_Llama-3.2-1B-Instruct_t3k_2025-06-02_09-20-54_isl-16000_osl-64_maxcon-32_n-64.json"
        }
    ]
}